{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of free apps in the Google Play store and App Store\n",
    "\n",
    "* This project will analyze data of free Android and Apple apps\n",
    "* Goal of the project- to help developers understand what types of apps are likely to attract more users and which will generate the most advertising revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openapplestorefile = open('AppleStore.csv')\n",
    "opengooglestorefile = open('googleplaystore.csv')\n",
    "\n",
    "from csv import reader\n",
    "apple_read_file = reader(openapplestorefile)\n",
    "apple_apps_data = list(apple_read_file)\n",
    "\n",
    "from csv import reader\n",
    "google_read_file = reader(opengooglestorefile)\n",
    "google_apps_data = list(google_read_file)\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "explore_data(apple_apps_data, 0, 4, rows_and_columns=True)\n",
    "print('\\n')\n",
    "explore_data(google_apps_data, 0, 4, rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting inaccurate data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 1 row in the Google Play Store dataset that is missing information. The following code deletes that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(google_apps_data))\n",
    "del google_apps_data[10473]\n",
    "print(len(google_apps_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks to see if the App Store dataset has any rows whose length deviates from the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_header = apple_apps_data[0]\n",
    "\n",
    "for row in apple_apps_data:\n",
    "    if len(row) != len(apple_header):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting duplicate data\n",
    "\n",
    "The Google Play store data has duplicate data. Below is a sample of some of the duplicate rows found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "for row in google_apps_data[1:]:\n",
    "    app_name = row[0]\n",
    "    if app_name in unique_apps:\n",
    "        duplicate_apps.append(app_name)\n",
    "    else:\n",
    "        unique_apps.append(app_name)\n",
    "        \n",
    "print('Number of duplicate apps: ', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Number of unique apps: ', len(unique_apps))\n",
    "print('\\n')\n",
    "print('Sample of duplicate data: ', duplicate_apps[0:4])\n",
    "print('\\n')\n",
    "print('Expected length of dataset with duplicates removed: ', (len(unique_apps) - 1181))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicate data will not be deleted randomly. The apps data with the highest number of user reviews will be kept and the remaining apps data deleted. This allows us to keep the most up-to-date data in our dataset.\n",
    "\n",
    "The code below creates a dictionary of the highest amounts of user reviews for each unique app in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for row in google_apps_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "    \n",
    "print('The length of remove_max dictionary is: ', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below identifies the data for each app in the dataset that contains the highest number of reviews. The entire row for the data with the highest number of reviews is added to the android_clean list to create a list of lists. Then the name of the each app from android_clean is added to already_added. This eliminates duplicate data from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for row in google_apps_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        android_clean.append(row)\n",
    "        already_added.append(name)\n",
    "\n",
    "print('Sample of android_clean list: ', android_clean[0:4])\n",
    "print('\\n')\n",
    "print('Sample of already_added list: ', already_added[0:5])\n",
    "print('\\n')\n",
    "print('The length of android_clean list is: ', len(android_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of these datasets, we are only interested in identifying apps whose names are written in English. In the code below, we use a loop to identify if the characters in a string are in English based on their assigned ASCII numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Instagram in English?:  True\n",
      "Is Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠ in English?:  False\n",
      "Is Docs To Go‚Ñ¢ Free Office Suite in English?:  True\n"
     ]
    }
   ],
   "source": [
    "def special_characters(string):\n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "print('Is Instagram in English?: ', special_characters('Instagram'))\n",
    "print('Is Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠ in English?: ', special_characters('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print('Is Docs To Go‚Ñ¢ Free Office Suite in English?: ', special_characters('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "#print('Is Instachat üòú in English?: ', special_characters('Instachat üòú')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
